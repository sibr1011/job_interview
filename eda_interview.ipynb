{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba88acf7-3ece-4a56-b3d0-c4a8b1c8df97",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# create features\n",
    "# write functions \n",
    "# 1. time to next appointment\n",
    "# 2. split date and time into 2 columns\n",
    "# 3. create treatment col (there seems to be different treatment processes)\n",
    "# 4. patient number as own col\n",
    "# 5. current step in treatment procedure\n",
    "# 6. treatment procedure classifier (a,b,c,d)\n",
    "# create \"patient / date - gantt in power bi\"\n",
    "# time series datacamp for ideas\n",
    "# interview questions datacamp for preparation\n",
    "# Questions\n",
    "# - why use hive?\n",
    "# - why use apache spark?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c56285e8-d7ba-491d-9318-286516d75155",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# JOB Interview - Data Analyst\n",
    "\n",
    "Welcome to this notebook! Here I present the approach I took to analyse the dataset the interviewers sent to me during a \"Data Analyst\" job interview process. The R&D department operates in the healthcare sector and produces hearing aids for B2B. The following steps were taken:\n",
    "<br><br>\n",
    "1. Understanding the Problem & Setting the Scene\n",
    "2. Setting up the infrastructure\n",
    "3. Getting Data\n",
    "4. Exploratory Data Analysis - Python\n",
    "    1. Sneak Peak\n",
    "    2. Types of columns & description\n",
    "    3. Descriptive Statistics\n",
    "    4. Plots & Questions\n",
    "    5. Outlier Detection\n",
    "5. Feature Engineering\n",
    "6. Interpretation\n",
    "7. Future Work & Limitations\n",
    "8. Sources Used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ab9d4a2-2b12-4639-8ec6-6c20bbe8a6e5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 1. Understanding the Problem\n",
    "\n",
    "The interviewers have provided a dataset in the ```.csv```-format to the potential candidate (me). The formulated task, by the interviewers, is to \"showcase your skills and investigate the dataset\". The interview is scheduled to take place a week after receiving the dataset. In this appointment the interviewee will need to present his results. Emphasis is placed on written code. <b>No further instructions have been made. </b> The R&D department offering the Data Analyst position are looking for support due to the growing amount of requests.\n",
    "\n",
    "However, the interviewee has deducted that the following requirements need to be met to some extent, in order for him to proceed to the interview stage 2. He also wants to use this interview as an opportunity to learn new things. He bases his assumptions on information provided in a screening interview and the job position:\n",
    "\n",
    "  * a) Company language is English, therefore code and explanations should meet this requirement\n",
    "  * b) Programming skills in Python, SQL as well Power BI (DAX / M-Language) should be incorporated, as the department relies on these for coding\n",
    "  * c) Coding principles should be followed (\"Commit early, commit often\", commented code, clean code)\n",
    "  * d) Deliver high quality analytics in easy and understandable way\n",
    "  * e) Answering common data analytics questions using EDA for the dataset\n",
    "  * f) Data pipelines should be implemented\n",
    "  * g) Utilizing Apache Spark (pyspark), Azure Services and ML methods are icing on the cake!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e17b6c0-df5a-4455-ac36-93b2750667e5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 2. Setting up the infrastructure\n",
    "\n",
    "[![IMAGE ALT TEXT HERE](https://github.com/sibr1011/job_interview/blob/main/pics/pipeline.png?raw=true)](https://github.com/sibr1011/job_interview/blob/main/pics/pipeline.png?raw=true)\n",
    "\n",
    "The image above illustrates the process that was taken for the task at hand. The provided ```.csv``` was uploaded to github. In this notebook we read the file directly into spark. After feature generation and cleaning has taken place, we will store the date in a Hive Database.\n",
    "\n",
    "This section focues on Problems f) and partly g) from section *1. Understanding the Problem.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1b7c87c-e05b-4e3e-a915-a5e82e7e89a0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 3. Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d89f5c4-35f8-4721-adbb-753adaffd3d6",
     "showTitle": true,
     "title": "Getting Data"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pyspark as ps\n",
    "from pyspark.sql.types import StructField, StructType, DateType, StringType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark import SparkFiles\n",
    "from functools import reduce\n",
    "import sys\n",
    "\n",
    "\n",
    "# url for csv\n",
    "url = \"https://raw.githubusercontent.com/sibr1011/job_interview/main/WSA_jobinterviewdata.csv\"\n",
    "\n",
    "# variables for writing back later\n",
    "appName= \"hive_metastore\"\n",
    "master= \"local\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68f62ef1-887c-4450-8c43-3a8b7fd9f7a6",
     "showTitle": true,
     "title": "Getting Data"
    }
   },
   "outputs": [],
   "source": [
    "# initialize session for writing data back later\n",
    "spark = SparkSession.builder.appName('Interview CSV').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffbf8a76-0678-4041-988e-17089506639a",
     "showTitle": true,
     "title": "Getting Data"
    }
   },
   "outputs": [],
   "source": [
    "# loading data from csv to pyspark df\n",
    "spark.sparkContext.addFile(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8422eb53-a3a7-459b-af0f-ddb729017460",
     "showTitle": true,
     "title": "Getting Data"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[69]: '/local_disk0/spark-8147a724-b3ba-4bb5-a292-8b56c479a898/userFiles-f747ea0f-afd0-4ca7-b832-135ab88364b5'"
     ]
    }
   ],
   "source": [
    "# seems to be a bug where the file lands -> https://stackoverflow.com/questions/70246983/sparkfiles-path-not-found\n",
    "SparkFiles.getRootDirectory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a31a107f-a660-48e7-b862-89b5653c3174",
     "showTitle": true,
     "title": "Getting Data"
    }
   },
   "outputs": [],
   "source": [
    "# read the file with schema\n",
    "df = spark.read.csv(SparkFiles.get(\"/local_disk0/WSA_jobinterviewdata.csv\"), inferSchema=True, header=True)\n",
    "\n",
    "# rename cols\n",
    "old_col_names = df.schema.names\n",
    "new_col_names = [\"patient\", \"action\", \"org_resource\", \"date_time\"]\n",
    "df = reduce(lambda df, idx: df.withColumnRenamed(old_col_names[idx], new_col_names[idx]), range(len(old_col_names)), df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db9902da-1e32-4250-a680-4584c7fc611c",
     "showTitle": true,
     "title": "Getting Data"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- patient: string (nullable = true)\n |-- action: string (nullable = true)\n |-- org_resource: string (nullable = true)\n |-- date_time: timestamp (nullable = true)\n\nNone\n"
     ]
    }
   ],
   "source": [
    "# now the schema is the way we want it\n",
    "print(df.printSchema())\n",
    "\n",
    "# create pandasDF just for fun\n",
    "pandasDF = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56034323-be90-4361-9e91-248b2d4c6c99",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[72]: pyspark.sql.dataframe.DataFrame"
     ]
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c201f1f-20be-49f7-92c1-4c40cf529e5a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 4. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe8fe4e7-e456-4794-8e69-fabb6ef27393",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4.1 Sneak Peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20902dd4-e881-4a85-a697-21338365f1ae",
     "showTitle": false,
     "title": "Sneak Peak"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records ct:  690\ncolumns ct:  4\n"
     ]
    }
   ],
   "source": [
    "# 1. shape / counts -> 690 rows, 4 columns\n",
    "print(\"records ct: \", df.count())\n",
    "print(\"columns ct: \", sum(1 for x in df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eac0d0b4-2026-49c2-8909-cd5617b75490",
     "showTitle": false,
     "title": "Sneak Peak"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient</th>\n",
       "      <th>action</th>\n",
       "      <th>org_resource</th>\n",
       "      <th>date_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patient 0</td>\n",
       "      <td>First consult</td>\n",
       "      <td>Dr. Anna</td>\n",
       "      <td>2017-01-02 11:40:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>patient 0</td>\n",
       "      <td>Blood test</td>\n",
       "      <td>Lab</td>\n",
       "      <td>2017-01-02 12:47:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>patient 0</td>\n",
       "      <td>Physical test</td>\n",
       "      <td>Nurse Jesse</td>\n",
       "      <td>2017-01-02 12:53:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>patient 0</td>\n",
       "      <td>Second consult</td>\n",
       "      <td>Dr. Anna</td>\n",
       "      <td>2017-01-02 16:21:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>patient 0</td>\n",
       "      <td>Surgery</td>\n",
       "      <td>Dr. Charlie</td>\n",
       "      <td>2017-01-05 13:23:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>patient 0</td>\n",
       "      <td>Final consult</td>\n",
       "      <td>Dr. Ben</td>\n",
       "      <td>2017-01-09 08:29:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>patient 1</td>\n",
       "      <td>First consult</td>\n",
       "      <td>Dr. Anna</td>\n",
       "      <td>2017-01-02 12:50:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>patient 1</td>\n",
       "      <td>Physical test</td>\n",
       "      <td>Nurse Jesse</td>\n",
       "      <td>2017-01-02 13:59:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>patient 1</td>\n",
       "      <td>Blood test</td>\n",
       "      <td>Lab</td>\n",
       "      <td>2017-01-02 14:20:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>patient 1</td>\n",
       "      <td>X-ray scan</td>\n",
       "      <td>Team 1</td>\n",
       "      <td>2017-01-06 09:13:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient</th>\n      <th>action</th>\n      <th>org_resource</th>\n      <th>date_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>patient 0</td>\n      <td>First consult</td>\n      <td>Dr. Anna</td>\n      <td>2017-01-02 11:40:11</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>patient 0</td>\n      <td>Blood test</td>\n      <td>Lab</td>\n      <td>2017-01-02 12:47:33</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>patient 0</td>\n      <td>Physical test</td>\n      <td>Nurse Jesse</td>\n      <td>2017-01-02 12:53:50</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>patient 0</td>\n      <td>Second consult</td>\n      <td>Dr. Anna</td>\n      <td>2017-01-02 16:21:06</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>patient 0</td>\n      <td>Surgery</td>\n      <td>Dr. Charlie</td>\n      <td>2017-01-05 13:23:09</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>patient 0</td>\n      <td>Final consult</td>\n      <td>Dr. Ben</td>\n      <td>2017-01-09 08:29:28</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>patient 1</td>\n      <td>First consult</td>\n      <td>Dr. Anna</td>\n      <td>2017-01-02 12:50:35</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>patient 1</td>\n      <td>Physical test</td>\n      <td>Nurse Jesse</td>\n      <td>2017-01-02 13:59:14</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>patient 1</td>\n      <td>Blood test</td>\n      <td>Lab</td>\n      <td>2017-01-02 14:20:19</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>patient 1</td>\n      <td>X-ray scan</td>\n      <td>Team 1</td>\n      <td>2017-01-06 09:13:40</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. head() - i think the output looks better in pandas df\n",
    "pandasDF.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c3ccb2a-7905-42e7-9702-0b9ca69016ec",
     "showTitle": false,
     "title": "Sneak Peak"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient</th>\n",
       "      <th>action</th>\n",
       "      <th>org_resource</th>\n",
       "      <th>date_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>patient 98</td>\n",
       "      <td>Second consult</td>\n",
       "      <td>Dr. Anna</td>\n",
       "      <td>2017-05-26 11:53:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>patient 98</td>\n",
       "      <td>Surgery</td>\n",
       "      <td>Dr. Alex</td>\n",
       "      <td>2017-05-30 14:13:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>patient 98</td>\n",
       "      <td>Final consult</td>\n",
       "      <td>Dr. Ben</td>\n",
       "      <td>2017-05-31 14:16:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>patient 99</td>\n",
       "      <td>First consult</td>\n",
       "      <td>Dr. Bob</td>\n",
       "      <td>2017-05-18 11:57:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>patient 99</td>\n",
       "      <td>Blood test</td>\n",
       "      <td>Lab</td>\n",
       "      <td>2017-05-18 13:13:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>patient 99</td>\n",
       "      <td>X-ray scan</td>\n",
       "      <td>Team 2</td>\n",
       "      <td>2017-05-25 11:03:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>patient 99</td>\n",
       "      <td>Physical test</td>\n",
       "      <td>Nurse Corey</td>\n",
       "      <td>2017-05-25 11:55:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>patient 99</td>\n",
       "      <td>Second consult</td>\n",
       "      <td>Dr. Anna</td>\n",
       "      <td>2017-05-29 15:12:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>patient 99</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>Pharmacy</td>\n",
       "      <td>2017-05-29 16:17:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>patient 99</td>\n",
       "      <td>Final consult</td>\n",
       "      <td>Dr. Anna</td>\n",
       "      <td>2017-05-31 12:46:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient</th>\n      <th>action</th>\n      <th>org_resource</th>\n      <th>date_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>680</th>\n      <td>patient 98</td>\n      <td>Second consult</td>\n      <td>Dr. Anna</td>\n      <td>2017-05-26 11:53:12</td>\n    </tr>\n    <tr>\n      <th>681</th>\n      <td>patient 98</td>\n      <td>Surgery</td>\n      <td>Dr. Alex</td>\n      <td>2017-05-30 14:13:17</td>\n    </tr>\n    <tr>\n      <th>682</th>\n      <td>patient 98</td>\n      <td>Final consult</td>\n      <td>Dr. Ben</td>\n      <td>2017-05-31 14:16:13</td>\n    </tr>\n    <tr>\n      <th>683</th>\n      <td>patient 99</td>\n      <td>First consult</td>\n      <td>Dr. Bob</td>\n      <td>2017-05-18 11:57:11</td>\n    </tr>\n    <tr>\n      <th>684</th>\n      <td>patient 99</td>\n      <td>Blood test</td>\n      <td>Lab</td>\n      <td>2017-05-18 13:13:44</td>\n    </tr>\n    <tr>\n      <th>685</th>\n      <td>patient 99</td>\n      <td>X-ray scan</td>\n      <td>Team 2</td>\n      <td>2017-05-25 11:03:27</td>\n    </tr>\n    <tr>\n      <th>686</th>\n      <td>patient 99</td>\n      <td>Physical test</td>\n      <td>Nurse Corey</td>\n      <td>2017-05-25 11:55:24</td>\n    </tr>\n    <tr>\n      <th>687</th>\n      <td>patient 99</td>\n      <td>Second consult</td>\n      <td>Dr. Anna</td>\n      <td>2017-05-29 15:12:39</td>\n    </tr>\n    <tr>\n      <th>688</th>\n      <td>patient 99</td>\n      <td>Medicine</td>\n      <td>Pharmacy</td>\n      <td>2017-05-29 16:17:13</td>\n    </tr>\n    <tr>\n      <th>689</th>\n      <td>patient 99</td>\n      <td>Final consult</td>\n      <td>Dr. Anna</td>\n      <td>2017-05-31 12:46:43</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. tail - same here\n",
    "pandasDF.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00cc8f2e-907a-4ecf-b28b-9b6b3ad069bf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4.2 Types of columns and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbde37c9-ac30-4c3b-a88b-93c045fd55c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['patient', 'action', 'org_resource', 'date_time']\n"
     ]
    }
   ],
   "source": [
    "# schema - 4 vars.\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42e266ce-d58a-4c06-96fd-7c90a6615955",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4.3 Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77aebad7-e974-4836-a542-7b2540964b47",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n|summary|   patient|\n+-------+----------+\n|  count|       690|\n|   mean|      null|\n| stddev|      null|\n|    min| patient 0|\n|    max|patient 99|\n+-------+----------+\n\nNone\n+-------+-----------+\n|summary|     action|\n+-------+-----------+\n|  count|        690|\n|   mean|       null|\n| stddev|       null|\n|    min| Blood test|\n|    max| X-ray scan|\n+-------+-----------+\n\nNone\n+-------+------------+\n|summary|org_resource|\n+-------+------------+\n|  count|         690|\n|   mean|        null|\n| stddev|        null|\n|    min|    Dr. Alex|\n|    max|      Team 2|\n+-------+------------+\n\nNone\n+-------+\n|summary|\n+-------+\n|  count|\n|   mean|\n| stddev|\n|    min|\n|    max|\n+-------+\n\nNone\n"
     ]
    }
   ],
   "source": [
    "# get descriptive statistics for all columns\n",
    "print(df.select('patient').describe().show())\n",
    "print(df.select('action').describe().show())\n",
    "print(df.select('org_resource').describe().show())\n",
    "print(df.select('date_time').describe().show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6921891c-0b9b-46e3-a487-12d625b1dc49",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# any missing values?\n",
    "print(pandasDF.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76a9dc38-1f13-46d2-9914-7a7b26bbd8ba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# get distinct amount of patients / actions / resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4185ad3a-9dfc-49f4-966f-f7bfd92ac344",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4.4 Plots & Questions\n",
    "- count plot of actions vs patients altogether\n",
    "- count plot of resources vs. patients\n",
    "- What are the different treamtment procedures and how many steps does each procedure have\n",
    "- how much time does a patient spend in the system on avg\n",
    "- how much time is spent in system per treatment workflow\n",
    "- how many counts of patients does each treatment workflow have\n",
    "- timeframe of the data (2017)\n",
    "- what time do treatments usually happen\n",
    "- which resource has the most to do?\n",
    "- which resource does which task?\n",
    "- what are the distinct amount of patients\n",
    "- (optional) which illnesses are the treatments trying to solve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00f59586-8797-4c8d-b084-e1928c2995cf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 6. Interpretation\n",
    "-"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3356029326586796,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "eda_interview",
   "notebookOrigID": 820328469684603,
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
